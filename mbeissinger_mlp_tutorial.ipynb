{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Yet Another MLP Example with Theano\n",
    "\n",
    "Adapted from: https://github.com/mbeissinger/intro_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "# Download and unzip pickled version from here: http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = pickle.load(gzip.open('data/mnist.pkl.gz', 'rb'))\n",
    "print \"Shapes:\"\n",
    "print train_x.shape, train_y.shape\n",
    "print valid_x.shape, valid_y.shape\n",
    "print test_x.shape, test_y.shape\n",
    "\n",
    "# print \"--------------\"\n",
    "# print \"Example input:\"\n",
    "# print train_x[0]\n",
    "# print \"Example label:\"\n",
    "# print train_y[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Show example images - using tile_raster_images helper function from OpenDeep to get 28x28 image from 784 array.\n",
    "from utils import tile_raster_images\n",
    "from PIL import Image as pil_img\n",
    "\n",
    "input_images = train_x[:25]\n",
    "im = pil_img.fromarray(\n",
    "    tile_raster_images(input_images, \n",
    "                       img_shape=(28, 28), \n",
    "                       tile_shape=(1, 25),\n",
    "                       tile_spacing=(1, 1))\n",
    ")\n",
    "im.save(\"some_mnist_numbers.png\")\n",
    "Image(filename=\"some_mnist_numbers.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Your basic Theano imports.\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "x = T.matrix('x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_nodes = 50\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute the hidden layer from the input\n",
    "import numpy\n",
    "import numpy.random as rng\n",
    "\n",
    "i = numpy.sqrt(6. / (input_size+hidden_nodes))\n",
    "# W_x = numpy.asarray(rng.normal(loc=0.0, scale=.05, size=(input_size, hidden_nodes)), dtype=theano.config.floatX)\n",
    "W_x = numpy.asarray(rng.uniform(low=-i, high=i, size=(input_size, hidden_nodes)), dtype=theano.config.floatX)\n",
    "b_h = numpy.zeros(shape=(hidden_nodes,), dtype=theano.config.floatX)\n",
    "\n",
    "W_x = theano.shared(W_x, name=\"W_x\")\n",
    "b_h = theano.shared(b_h, name=\"b_h\")\n",
    "\n",
    "h = T.tanh(\n",
    "    T.dot(x, W_x) + b_h\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute the output class probabilities from the hidden layer\n",
    "i = numpy.sqrt(6. / (hidden_nodes+output_size))\n",
    "# W_h = numpy.asarray(rng.normal(loc=0.0, scale=.05, size=(hidden_nodes, output_size)), dtype=theano.config.floatX)\n",
    "W_h = numpy.asarray(rng.uniform(low=-i, high=i, size=(hidden_nodes, output_size)), dtype=theano.config.floatX)\n",
    "b_y = numpy.zeros(shape=(output_size,), dtype=\"float32\")\n",
    "\n",
    "W_h = theano.shared(W_h, name=\"W_h\")\n",
    "b_y = theano.shared(b_y, name=\"b_y\")\n",
    "\n",
    "y = T.nnet.softmax(\n",
    "    T.dot(h, W_h) + b_y\n",
    ")\n",
    "\n",
    "# The actual predicted label\n",
    "y_hat = T.argmax(y, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find cost compared to correct labels\n",
    "correct_labels = T.ivector(\"labels\")\n",
    "\n",
    "log_likelihood = T.log(y)[T.arange(correct_labels.shape[0]), correct_labels]\n",
    "cost = -T.mean(log_likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute gradient updates for the parameters\n",
    "parameters = [W_x, b_h, W_h, b_y]\n",
    "gradients = T.grad(cost, parameters)\n",
    "\n",
    "learning_rate = 0.01\n",
    "train_updates = [(param, param - learning_rate*gradient) for param, gradient in zip(parameters, gradients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compile function for training (changes parameters via updates) and testing (no updates)\n",
    "f_train = theano.function(\n",
    "    inputs=[x, correct_labels], \n",
    "    outputs=cost, \n",
    "    updates=train_updates, \n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f_test = theano.function(\n",
    "    inputs=[x], \n",
    "    outputs=y_hat, \n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(batch_size=100, epochs=100, check_frequency=3):\n",
    "    # Main training loop\n",
    "    train_batches = len(train_x) / batch_size\n",
    "    valid_batches = len(valid_x) / batch_size\n",
    "    test_batches = len(test_x) / batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print epoch+1, \":\",\n",
    "\n",
    "        train_costs = []\n",
    "        train_accuracy = []\n",
    "        for i in range(train_batches):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = train_y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            costs = f_train(batch_x, batch_labels)\n",
    "            preds = f_test(batch_x)\n",
    "            acc = sum(preds==batch_labels)/float(len(batch_labels))\n",
    "\n",
    "            train_costs.append(costs)\n",
    "            train_accuracy.append(acc)\n",
    "        print \"cost:\", numpy.mean(train_costs), \"\\ttrain:\", str(numpy.mean(train_accuracy)*100)+\"%\",\n",
    "\n",
    "        valid_accuracy = []\n",
    "        for i in range(valid_batches):\n",
    "            batch_x = valid_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = valid_y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            preds = f_test(batch_x)\n",
    "            acc = sum(preds==batch_labels)/float(len(batch_labels))\n",
    "\n",
    "            valid_accuracy.append(acc)\n",
    "        print \"\\tvalid:\", str(numpy.mean(valid_accuracy)*100)+\"%\",\n",
    "\n",
    "        test_accuracy = []\n",
    "        for i in range(test_batches):\n",
    "            batch_x = test_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = test_y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            preds = f_test(batch_x)\n",
    "            acc = sum(preds==batch_labels)/float(len(batch_labels))\n",
    "\n",
    "            test_accuracy.append(acc)\n",
    "        print \"\\ttest:\", str(numpy.mean(test_accuracy)*100)+\"%\"\n",
    "\n",
    "        if (epoch+1) % check_frequency == 0:\n",
    "            print 'saving filters...'\n",
    "            weight_filters = pil_img.fromarray(\n",
    "                    tile_raster_images(\n",
    "                        W_x.get_value(borrow=True).T,\n",
    "                        img_shape=(28, 28),\n",
    "#                         tile_shape=(20, 25),\n",
    "                        tile_shape=(7, 8),\n",
    "                        tile_spacing=(1, 1)\n",
    "                    )\n",
    "                )\n",
    "            weight_filters.save(\"mlp_filters_%d.png\"%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "run(batch_size=100, epochs=200, check_frequency=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
