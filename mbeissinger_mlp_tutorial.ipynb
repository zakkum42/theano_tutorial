{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "(50000, 784) (50000,)\n",
      "(10000, 784) (10000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import pickle\n",
    "\n",
    "# Download and unzip pickled version from here: http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = pickle.load(open('mnist.pkl', 'rb'))\n",
    "print \"Shapes:\"\n",
    "print train_x.shape, train_y.shape\n",
    "print valid_x.shape, valid_y.shape\n",
    "print test_x.shape, test_y.shape\n",
    "\n",
    "# print \"--------------\"\n",
    "# print \"Example input:\"\n",
    "# print train_x[0]\n",
    "# print \"Example label:\"\n",
    "# print train_y[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAAcCAAAAABkYnfcAAAQtklEQVR4nO1beVxV5dZ+EgQHUJFS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\nQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show example images - using tile_raster_images helper function from OpenDeep to get 28x28 image from 784 array.\n",
    "from utils import tile_raster_images\n",
    "from PIL import Image as pil_img\n",
    "\n",
    "input_images = train_x[:25]\n",
    "im = pil_img.fromarray(\n",
    "    tile_raster_images(input_images, \n",
    "                       img_shape=(28, 28), \n",
    "                       tile_shape=(1, 25),\n",
    "                       tile_spacing=(1, 1))\n",
    ")\n",
    "im.save(\"some_mnist_numbers.png\")\n",
    "Image(filename=\"some_mnist_numbers.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your basic Theano imports.\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "x = T.matrix('x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_nodes = 50\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the hidden layer from the input\n",
    "import numpy\n",
    "import numpy.random as rng\n",
    "\n",
    "i = numpy.sqrt(6. / (input_size+hidden_nodes))\n",
    "# W_x = numpy.asarray(rng.normal(loc=0.0, scale=.05, size=(input_size, hidden_nodes)), dtype=theano.config.floatX)\n",
    "W_x = numpy.asarray(rng.uniform(low=-i, high=i, size=(input_size, hidden_nodes)), dtype=theano.config.floatX)\n",
    "b_h = numpy.zeros(shape=(hidden_nodes,), dtype=theano.config.floatX)\n",
    "\n",
    "W_x = theano.shared(W_x, name=\"W_x\")\n",
    "b_h = theano.shared(b_h, name=\"b_h\")\n",
    "\n",
    "h = T.tanh(\n",
    "    T.dot(x, W_x) + b_h\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the output class probabilities from the hidden layer\n",
    "i = numpy.sqrt(6. / (hidden_nodes+output_size))\n",
    "# W_h = numpy.asarray(rng.normal(loc=0.0, scale=.05, size=(hidden_nodes, output_size)), dtype=theano.config.floatX)\n",
    "W_h = numpy.asarray(rng.uniform(low=-i, high=i, size=(hidden_nodes, output_size)), dtype=theano.config.floatX)\n",
    "b_y = numpy.zeros(shape=(output_size,), dtype=\"float32\")\n",
    "\n",
    "W_h = theano.shared(W_h, name=\"W_h\")\n",
    "b_y = theano.shared(b_y, name=\"b_y\")\n",
    "\n",
    "y = T.nnet.softmax(\n",
    "    T.dot(h, W_h) + b_y\n",
    ")\n",
    "\n",
    "# The actual predicted label\n",
    "y_hat = T.argmax(y, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find cost compared to correct labels\n",
    "correct_labels = T.ivector(\"labels\")\n",
    "\n",
    "log_likelihood = T.log(y)[T.arange(correct_labels.shape[0]), correct_labels]\n",
    "cost = -T.mean(log_likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute gradient updates for the parameters\n",
    "parameters = [W_x, b_h, W_h, b_y]\n",
    "gradients = T.grad(cost, parameters)\n",
    "\n",
    "learning_rate = 0.01\n",
    "train_updates = [(param, param - learning_rate*gradient) for param, gradient in zip(parameters, gradients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile function for training (changes parameters via updates) and testing (no updates)\n",
    "f_train = theano.function(\n",
    "    inputs=[x, correct_labels], \n",
    "    outputs=cost, \n",
    "    updates=train_updates, \n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_test = theano.function(\n",
    "    inputs=[x], \n",
    "    outputs=y_hat, \n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(batch_size=100, epochs=100, check_frequency=3):\n",
    "    # Main training loop\n",
    "    train_batches = len(train_x) / batch_size\n",
    "    valid_batches = len(valid_x) / batch_size\n",
    "    test_batches = len(test_x) / batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print epoch+1, \":\",\n",
    "\n",
    "        train_costs = []\n",
    "        train_accuracy = []\n",
    "        for i in range(train_batches):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = train_y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            costs = f_train(batch_x, batch_labels)\n",
    "            preds = f_test(batch_x)\n",
    "            acc = sum(preds==batch_labels)/float(len(batch_labels))\n",
    "\n",
    "            train_costs.append(costs)\n",
    "            train_accuracy.append(acc)\n",
    "        print \"cost:\", numpy.mean(train_costs), \"\\ttrain:\", str(numpy.mean(train_accuracy)*100)+\"%\",\n",
    "\n",
    "        valid_accuracy = []\n",
    "        for i in range(valid_batches):\n",
    "            batch_x = valid_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = valid_y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            preds = f_test(batch_x)\n",
    "            acc = sum(preds==batch_labels)/float(len(batch_labels))\n",
    "\n",
    "            valid_accuracy.append(acc)\n",
    "        print \"\\tvalid:\", str(numpy.mean(valid_accuracy)*100)+\"%\",\n",
    "\n",
    "        test_accuracy = []\n",
    "        for i in range(test_batches):\n",
    "            batch_x = test_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = test_y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            preds = f_test(batch_x)\n",
    "            acc = sum(preds==batch_labels)/float(len(batch_labels))\n",
    "\n",
    "            test_accuracy.append(acc)\n",
    "        print \"\\ttest:\", str(numpy.mean(test_accuracy)*100)+\"%\"\n",
    "\n",
    "        if (epoch+1) % check_frequency == 0:\n",
    "            print 'saving filters...'\n",
    "            weight_filters = pil_img.fromarray(\n",
    "                    tile_raster_images(\n",
    "                        W_x.get_value(borrow=True).T,\n",
    "                        img_shape=(28, 28),\n",
    "#                         tile_shape=(20, 25),\n",
    "                        tile_shape=(7, 8),\n",
    "                        tile_spacing=(1, 1)\n",
    "                    )\n",
    "                )\n",
    "            weight_filters.save(\"mlp_filters_%d.png\"%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : cost: 1.11102 \ttrain: 73.69% \tvalid: 85.5% \ttest: 84.6%\n",
      "2 : cost: 0.601599 \ttrain: 85.644% \tvalid: 88.36% \ttest: 87.83%\n",
      "3 : cost: 0.485071 \ttrain: 87.768% \tvalid: 89.62% \ttest: 89.13%\n",
      "saving filters...\n",
      "4 : cost: 0.42829 \ttrain: 88.766% \tvalid: 90.24% \ttest: 89.8%\n",
      "5 : cost: 0.3936 \ttrain: 89.436% \tvalid: 90.71% \ttest: 90.39%\n",
      "6 : cost: 0.369611 \ttrain: 89.972% \tvalid: 91.04% \ttest: 90.91%\n",
      "saving filters...\n",
      "7 : cost: 0.351627 \ttrain: 90.36% \tvalid: 91.44% \ttest: 91.15%\n",
      "8 : cost: 0.337356 \ttrain: 90.716% \tvalid: 91.71% \ttest: 91.39%\n",
      "9 : cost: 0.325543 \ttrain: 90.986% \tvalid: 91.91% \ttest: 91.57%\n",
      "saving filters...\n",
      "10 : cost: 0.315444 \ttrain: 91.248% \tvalid: 92.1% \ttest: 91.71%\n",
      "11 : cost: 0.306593 \ttrain: 91.512% \tvalid: 92.27% \ttest: 91.9%\n",
      "12 : cost: 0.298681 \ttrain: 91.72% \tvalid: 92.4% \ttest: 92.07%\n",
      "saving filters...\n",
      "13 : cost: 0.291497 \ttrain: 91.89% \tvalid: 92.6% \ttest: 92.3%\n",
      "14 : cost: 0.284895 \ttrain: 92.066% \tvalid: 92.67% \ttest: 92.41%\n",
      "15 : cost: 0.278767 \ttrain: 92.26% \tvalid: 92.7% \ttest: 92.55%\n",
      "saving filters...\n",
      "16 : cost: 0.273038 \ttrain: 92.43% \tvalid: 92.76% \ttest: 92.73%\n",
      "17 : cost: 0.26765 \ttrain: 92.556% \tvalid: 92.91% \ttest: 92.87%\n",
      "18 : cost: 0.26256 \ttrain: 92.704% \tvalid: 93.08% \ttest: 93.05%\n",
      "saving filters...\n",
      "19 : cost: 0.257733 \ttrain: 92.834% \tvalid: 93.12% \ttest: 93.2%\n",
      "20 : cost: 0.253143 \ttrain: 92.956% \tvalid: 93.24% \ttest: 93.32%\n",
      "21 : cost: 0.248768 \ttrain: 93.074% \tvalid: 93.38% \ttest: 93.49%\n",
      "saving filters...\n",
      "22 : cost: 0.24459 \ttrain: 93.198% \tvalid: 93.56% \ttest: 93.58%\n",
      "23 : cost: 0.240593 \ttrain: 93.338% \tvalid: 93.63% \ttest: 93.65%\n",
      "24 : cost: 0.236764 \ttrain: 93.452% \tvalid: 93.74% \ttest: 93.71%\n",
      "saving filters...\n",
      "25 : cost: 0.233091 \ttrain: 93.572% \tvalid: 93.82% \ttest: 93.79%\n",
      "26 : cost: 0.229562 \ttrain: 93.68% \tvalid: 93.91% \ttest: 93.87%\n",
      "27 : cost: 0.226169 \ttrain: 93.77% \tvalid: 93.97% \ttest: 93.97%\n",
      "saving filters...\n",
      "28 : cost: 0.222902 \ttrain: 93.85% \tvalid: 94.05% \ttest: 94.02%\n",
      "29 : cost: 0.219753 \ttrain: 93.932% \tvalid: 94.17% \ttest: 94.1%\n",
      "30 : cost: 0.216715 \ttrain: 94.01% \tvalid: 94.26% \ttest: 94.18%\n",
      "saving filters...\n",
      "31 : cost: 0.213781 \ttrain: 94.086% \tvalid: 94.3% \ttest: 94.26%\n",
      "32 : cost: 0.210945 \ttrain: 94.152% \tvalid: 94.38% \ttest: 94.31%\n",
      "33 : cost: 0.208201 \ttrain: 94.224% \tvalid: 94.46% \ttest: 94.32%\n",
      "saving filters...\n",
      "34 : cost: 0.205543 \ttrain: 94.312% \tvalid: 94.54% \ttest: 94.35%\n",
      "35 : cost: 0.202968 \ttrain: 94.39% \tvalid: 94.57% \ttest: 94.43%\n",
      "36 : cost: 0.200469 \ttrain: 94.454% \tvalid: 94.66% \ttest: 94.46%\n",
      "saving filters...\n",
      "37 : cost: 0.198043 \ttrain: 94.518% \tvalid: 94.74% \ttest: 94.54%\n",
      "38 : cost: 0.195687 \ttrain: 94.576% \tvalid: 94.79% \ttest: 94.6%\n",
      "39 : cost: 0.193395 \ttrain: 94.634% \tvalid: 94.83% \ttest: 94.68%\n",
      "saving filters...\n",
      "40 : cost: 0.191166 \ttrain: 94.696% \tvalid: 94.88% \ttest: 94.71%\n",
      "41 : cost: 0.188995 \ttrain: 94.768% \tvalid: 94.94% \ttest: 94.75%\n",
      "42 : cost: 0.186881 \ttrain: 94.852% \tvalid: 95.02% \ttest: 94.73%\n",
      "saving filters...\n",
      "43 : cost: 0.18482 \ttrain: 94.9% \tvalid: 95.06% \ttest: 94.77%\n",
      "44 : cost: 0.182809 \ttrain: 94.956% \tvalid: 95.12% \ttest: 94.8%\n",
      "45 : cost: 0.180848 \ttrain: 95.028% \tvalid: 95.23% \ttest: 94.82%\n",
      "saving filters...\n",
      "46 : cost: 0.178933 \ttrain: 95.106% \tvalid: 95.25% \ttest: 94.85%\n",
      "47 : cost: 0.177062 \ttrain: 95.166% \tvalid: 95.29% \ttest: 94.85%\n",
      "48 : cost: 0.175234 \ttrain: 95.202% \tvalid: 95.3% \ttest: 94.91%\n",
      "saving filters...\n",
      "49 : cost: 0.173447 \ttrain: 95.262% \tvalid: 95.34% \ttest: 94.94%\n",
      "50 : cost: 0.1717 \ttrain: 95.326% \tvalid: 95.42% \ttest: 94.98%\n",
      "51 : cost: 0.169991 \ttrain: 95.37% \tvalid: 95.45% \ttest: 95.01%\n",
      "saving filters...\n",
      "52 : cost: 0.168318 \ttrain: 95.42% \tvalid: 95.45% \ttest: 95.07%\n",
      "53 : cost: 0.166681 \ttrain: 95.464% \tvalid: 95.48% \ttest: 95.12%\n",
      "54 : cost: 0.165078 \ttrain: 95.51% \tvalid: 95.53% \ttest: 95.11%\n",
      "saving filters...\n",
      "55 : cost: 0.163507 \ttrain: 95.542% \tvalid: 95.6% \ttest: 95.18%\n",
      "56 : cost: 0.161969 \ttrain: 95.59% \tvalid: 95.6% \ttest: 95.23%\n",
      "57 : cost: 0.160462 \ttrain: 95.634% \tvalid: 95.65% \ttest: 95.26%\n",
      "saving filters...\n",
      "58 : cost: 0.158984 \ttrain: 95.674% \tvalid: 95.69% \ttest: 95.33%\n",
      "59 : cost: 0.157536 \ttrain: 95.714% \tvalid: 95.71% \ttest: 95.4%\n",
      "60 : cost: 0.156115 \ttrain: 95.742% \tvalid: 95.76% \ttest: 95.46%\n",
      "saving filters...\n",
      "61 : cost: 0.154722 \ttrain: 95.782% \tvalid: 95.78% \ttest: 95.48%\n",
      "62 : cost: 0.153355 \ttrain: 95.822% \tvalid: 95.8% \ttest: 95.51%\n",
      "63 : cost: 0.152014 \ttrain: 95.876% \tvalid: 95.83% \ttest: 95.53%\n",
      "saving filters...\n",
      "64 : cost: 0.150698 \ttrain: 95.904% \tvalid: 95.83% \ttest: 95.58%\n",
      "65 : cost: 0.149406 \ttrain: 95.936% \tvalid: 95.83% \ttest: 95.59%\n",
      "66 : cost: 0.148137 \ttrain: 95.968% \tvalid: 95.86% \ttest: 95.6%\n",
      "saving filters...\n",
      "67 : cost: 0.146891 \ttrain: 96.008% \tvalid: 95.9% \ttest: 95.65%\n",
      "68 : cost: 0.145668 \ttrain: 96.052% \tvalid: 95.89% \ttest: 95.69%\n",
      "69 : cost: 0.144466 \ttrain: 96.08% \tvalid: 95.89% \ttest: 95.73%\n",
      "saving filters...\n",
      "70 : cost: 0.143285 \ttrain: 96.108% \tvalid: 95.93% \ttest: 95.74%\n",
      "71 : cost: 0.142124 \ttrain: 96.138% \tvalid: 95.93% \ttest: 95.78%\n",
      "72 : cost: 0.140984 \ttrain: 96.176% \tvalid: 95.94% \ttest: 95.82%\n",
      "saving filters...\n",
      "73 : cost: 0.139862 \ttrain: 96.208% \tvalid: 95.98% \ttest: 95.81%\n",
      "74 : cost: 0.13876 \ttrain: 96.228% \tvalid: 96.0% \ttest: 95.87%\n",
      "75 : cost: 0.137675 \ttrain: 96.256% \tvalid: 96.0% \ttest: 95.9%\n",
      "saving filters...\n",
      "76 : cost: 0.136609 \ttrain: 96.282% \tvalid: 96.02% \ttest: 95.92%\n",
      "77 : cost: 0.13556 \ttrain: 96.322% \tvalid: 96.04% \ttest: 95.93%\n",
      "78 : cost: 0.134527 \ttrain: 96.346% \tvalid: 96.07% \ttest: 95.95%\n",
      "saving filters...\n",
      "79 : cost: 0.133512 \ttrain: 96.384% \tvalid: 96.09% \ttest: 95.96%\n",
      "80 : cost: 0.132512 \ttrain: 96.43% \tvalid: 96.12% \ttest: 95.97%\n",
      "81 : cost: 0.131527 \ttrain: 96.45% \tvalid: 96.12% \ttest: 96.03%\n",
      "saving filters...\n",
      "82 : cost: 0.130558 \ttrain: 96.494% \tvalid: 96.14% \ttest: 96.04%\n",
      "83 : cost: 0.129604 \ttrain: 96.508% \tvalid: 96.15% \ttest: 96.08%\n",
      "84 : cost: 0.128664 \ttrain: 96.54% \tvalid: 96.17% \ttest: 96.09%\n",
      "saving filters...\n",
      "85 : cost: 0.127739 \ttrain: 96.564% \tvalid: 96.21% \ttest: 96.13%\n",
      "86 : cost: 0.126827 \ttrain: 96.586% \tvalid: 96.2% \ttest: 96.15%\n",
      "87 : cost: 0.125928 \ttrain: 96.622% \tvalid: 96.21% \ttest: 96.17%\n",
      "saving filters...\n",
      "88 : cost: 0.125042 \ttrain: 96.646% \tvalid: 96.25% \ttest: 96.22%\n",
      "89 : cost: 0.12417 \ttrain: 96.672% \tvalid: 96.27% \ttest: 96.22%\n",
      "90 : cost: 0.123309 \ttrain: 96.714% \tvalid: 96.31% \ttest: 96.22%\n",
      "saving filters...\n",
      "91 : cost: 0.122461 \ttrain: 96.738% \tvalid: 96.33% \ttest: 96.23%\n",
      "92 : cost: 0.121625 \ttrain: 96.758% \tvalid: 96.33% \ttest: 96.28%\n",
      "93 : cost: 0.1208 \ttrain: 96.794% \tvalid: 96.36% \ttest: 96.29%\n",
      "saving filters...\n",
      "94 : cost: 0.119987 \ttrain: 96.812% \tvalid: 96.4% \ttest: 96.3%\n",
      "95 : cost: 0.119184 \ttrain: 96.822% \tvalid: 96.41% \ttest: 96.3%\n",
      "96 : cost: 0.118393 \ttrain: 96.85% \tvalid: 96.43% \ttest: 96.32%\n",
      "saving filters...\n",
      "97 : cost: 0.117612 \ttrain: 96.872% \tvalid: 96.44% \ttest: 96.34%\n",
      "98 : cost: 0.116841 \ttrain: 96.9% \tvalid: 96.45% \ttest: 96.34%\n",
      "99 : cost: 0.116081 \ttrain: 96.922% \tvalid: 96.49% \ttest: 96.34%\n",
      "saving filters...\n",
      "100 : cost: 0.11533 \ttrain: 96.94% \tvalid: 96.48% \ttest: 96.35%\n",
      "101 : cost: 0.11459 \ttrain: 96.956% \tvalid: 96.49% \ttest: 96.35%\n",
      "102 : cost: 0.113858 \ttrain: 96.98% \tvalid: 96.47% \ttest: 96.35%\n",
      "saving filters...\n",
      "103 : cost: 0.113136 \ttrain: 96.996% \tvalid: 96.48% \ttest: 96.35%\n",
      "104 : cost: 0.112423 \ttrain: 97.006% \tvalid: 96.49% \ttest: 96.36%\n",
      "105 : cost: 0.111719 \ttrain: 97.024% \tvalid: 96.49% \ttest: 96.36%\n",
      "saving filters...\n",
      "106 : cost: 0.111024 \ttrain: 97.054% \tvalid: 96.49% \ttest: 96.36%\n",
      "107 : cost: 0.110337 \ttrain: 97.07% \tvalid: 96.51% \ttest: 96.36%\n",
      "108 : cost: 0.109659 \ttrain: 97.086% \tvalid: 96.53% \ttest: 96.37%\n",
      "saving filters...\n",
      "109 : cost: 0.108988 \ttrain: 97.116% \tvalid: 96.54% \ttest: 96.39%\n",
      "110 : cost: 0.108326 \ttrain: 97.128% \tvalid: 96.58% \ttest: 96.4%\n",
      "111 : cost: 0.107672 \ttrain: 97.142% \tvalid: 96.61% \ttest: 96.4%\n",
      "saving filters...\n",
      "112 : cost: 0.107026 \ttrain: 97.16% \tvalid: 96.61% \ttest: 96.41%\n",
      "113 : cost: 0.106387 \ttrain: 97.176% \tvalid: 96.62% \ttest: 96.42%\n",
      "114 : cost: 0.105755 \ttrain: 97.196% \tvalid: 96.62% \ttest: 96.42%\n",
      "saving filters...\n",
      "115 : cost: 0.105131 \ttrain: 97.222% \tvalid: 96.63% \ttest: 96.42%\n",
      "116 : cost: 0.104515 \ttrain: 97.236% \tvalid: 96.65% \ttest: 96.42%\n",
      "117 : cost: 0.103905 \ttrain: 97.258% \tvalid: 96.66% \ttest: 96.41%\n",
      "saving filters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 : cost: 0.103302 \ttrain: 97.276% \tvalid: 96.69% \ttest: 96.44%\n",
      "119 : cost: 0.102706 \ttrain: 97.292% \tvalid: 96.71% \ttest: 96.45%\n",
      "120 : cost: 0.102117 \ttrain: 97.316% \tvalid: 96.72% \ttest: 96.45%\n",
      "saving filters...\n",
      "121 : cost: 0.101534 \ttrain: 97.328% \tvalid: 96.72% \ttest: 96.45%\n",
      "122 : cost: 0.100957 \ttrain: 97.346% \tvalid: 96.73% \ttest: 96.46%\n",
      "123 : cost: 0.100387 \ttrain: 97.364% \tvalid: 96.73% \ttest: 96.48%\n",
      "saving filters...\n",
      "124 : cost: 0.0998237 \ttrain: 97.372% \tvalid: 96.74% \ttest: 96.48%\n",
      "125 : cost: 0.0992661 \ttrain: 97.386% \tvalid: 96.77% \ttest: 96.48%\n",
      "126 : cost: 0.0987145 \ttrain: 97.402% \tvalid: 96.77% \ttest: 96.49%\n",
      "saving filters...\n",
      "127 : cost: 0.0981688 \ttrain: 97.422% \tvalid: 96.76% \ttest: 96.51%\n",
      "128 : cost: 0.097629 \ttrain: 97.442% \tvalid: 96.82% \ttest: 96.52%\n",
      "129 : cost: 0.0970949 \ttrain: 97.458% \tvalid: 96.82% \ttest: 96.53%\n",
      "saving filters...\n",
      "130 : cost: 0.0965664 \ttrain: 97.474% \tvalid: 96.83% \ttest: 96.55%\n",
      "131 : cost: 0.0960435 \ttrain: 97.496% \tvalid: 96.84% \ttest: 96.55%\n",
      "132 : cost: 0.0955261 \ttrain: 97.514% \tvalid: 96.83% \ttest: 96.55%\n",
      "saving filters...\n",
      "133 : cost: 0.095014 \ttrain: 97.53% \tvalid: 96.83% \ttest: 96.55%\n",
      "134 : cost: 0.0945072 \ttrain: 97.54% \tvalid: 96.83% \ttest: 96.56%\n",
      "135 : cost: 0.0940056 \ttrain: 97.556% \tvalid: 96.83% \ttest: 96.59%\n",
      "saving filters...\n",
      "136 : cost: 0.0935091 \ttrain: 97.572% \tvalid: 96.83% \ttest: 96.6%\n",
      "137 : cost: 0.0930176 \ttrain: 97.596% \tvalid: 96.83% \ttest: 96.61%\n",
      "138 : cost: 0.0925311 \ttrain: 97.606% \tvalid: 96.84% \ttest: 96.61%\n",
      "saving filters...\n",
      "139 : cost: 0.0920495 \ttrain: 97.622% \tvalid: 96.85% \ttest: 96.61%\n",
      "140 : cost: 0.0915727 \ttrain: 97.638% \tvalid: 96.84% \ttest: 96.62%\n",
      "141 : cost: 0.0911006 \ttrain: 97.644% \tvalid: 96.85% \ttest: 96.63%\n",
      "saving filters...\n",
      "142 : cost: 0.0906332 \ttrain: 97.658% \tvalid: 96.85% \ttest: 96.64%\n",
      "143 : cost: 0.0901704 \ttrain: 97.67% \tvalid: 96.85% \ttest: 96.64%\n",
      "144 : cost: 0.089712 \ttrain: 97.688% \tvalid: 96.85% \ttest: 96.65%\n",
      "saving filters...\n",
      "145 : cost: 0.0892582 \ttrain: 97.696% \tvalid: 96.88% \ttest: 96.65%\n",
      "146 : cost: 0.0888087 \ttrain: 97.71% \tvalid: 96.86% \ttest: 96.66%\n",
      "147 : cost: 0.0883635 \ttrain: 97.724% \tvalid: 96.87% \ttest: 96.67%\n",
      "saving filters...\n",
      "148 : cost: 0.0879226 \ttrain: 97.732% \tvalid: 96.87% \ttest: 96.68%\n",
      "149 : cost: 0.0874858 \ttrain: 97.748% \tvalid: 96.86% \ttest: 96.69%\n",
      "150 : cost: 0.0870532 \ttrain: 97.762% \tvalid: 96.86% \ttest: 96.72%\n",
      "saving filters...\n",
      "151 : cost: 0.0866247 \ttrain: 97.766% \tvalid: 96.86% \ttest: 96.71%\n",
      "152 : cost: 0.0862001 \ttrain: 97.778% \tvalid: 96.87% \ttest: 96.72%\n",
      "153 : cost: 0.0857795 \ttrain: 97.788% \tvalid: 96.87% \ttest: 96.73%\n",
      "saving filters...\n",
      "154 : cost: 0.0853628 \ttrain: 97.804% \tvalid: 96.88% \ttest: 96.73%\n",
      "155 : cost: 0.0849499 \ttrain: 97.822% \tvalid: 96.9% \ttest: 96.73%\n",
      "156 : cost: 0.0845408 \ttrain: 97.84% \tvalid: 96.9% \ttest: 96.73%\n",
      "saving filters...\n",
      "157 : cost: 0.0841354 \ttrain: 97.856% \tvalid: 96.91% \ttest: 96.75%\n",
      "158 : cost: 0.0837337 \ttrain: 97.864% \tvalid: 96.91% \ttest: 96.75%\n",
      "159 : cost: 0.0833356 \ttrain: 97.878% \tvalid: 96.92% \ttest: 96.75%\n",
      "saving filters...\n",
      "160 : cost: 0.0829411 \ttrain: 97.896% \tvalid: 96.9% \ttest: 96.77%\n",
      "161 : cost: 0.08255 \ttrain: 97.91% \tvalid: 96.91% \ttest: 96.78%\n",
      "162 : cost: 0.0821625 \ttrain: 97.922% \tvalid: 96.9% \ttest: 96.79%\n",
      "saving filters...\n",
      "163 : cost: 0.0817783 \ttrain: 97.93% \tvalid: 96.9% \ttest: 96.8%\n",
      "164 : cost: 0.0813976 \ttrain: 97.942% \tvalid: 96.91% \ttest: 96.81%\n",
      "165 : cost: 0.0810201 \ttrain: 97.956% \tvalid: 96.91% \ttest: 96.82%\n",
      "saving filters...\n",
      "166 : cost: 0.0806459 \ttrain: 97.966% \tvalid: 96.91% \ttest: 96.83%\n",
      "167 : cost: 0.080275 \ttrain: 97.974% \tvalid: 96.93% \ttest: 96.84%\n",
      "168 : cost: 0.0799073 \ttrain: 97.984% \tvalid: 96.93% \ttest: 96.85%\n",
      "saving filters...\n",
      "169 : cost: 0.0795427 \ttrain: 97.994% \tvalid: 96.94% \ttest: 96.83%\n",
      "170 : cost: 0.0791811 \ttrain: 98.006% \tvalid: 96.96% \ttest: 96.83%\n",
      "171 : cost: 0.0788227 \ttrain: 98.016% \tvalid: 96.96% \ttest: 96.84%\n",
      "saving filters...\n",
      "172 : cost: 0.0784673 \ttrain: 98.018% \tvalid: 96.96% \ttest: 96.84%\n",
      "173 : cost: 0.0781148 \ttrain: 98.028% \tvalid: 96.96% \ttest: 96.84%\n",
      "174 : cost: 0.0777653 \ttrain: 98.032% \tvalid: 96.97% \ttest: 96.86%\n",
      "saving filters...\n",
      "175 : cost: 0.0774187 \ttrain: 98.04% \tvalid: 96.95% \ttest: 96.86%\n",
      "176 : cost: 0.0770749 \ttrain: 98.048% \tvalid: 96.95% \ttest: 96.86%\n",
      "177 : cost: 0.076734 \ttrain: 98.066% \tvalid: 96.95% \ttest: 96.87%\n",
      "saving filters...\n",
      "178 : cost: 0.0763959 \ttrain: 98.072% \tvalid: 96.96% \ttest: 96.87%\n",
      "179 : cost: 0.0760605 \ttrain: 98.078% \tvalid: 96.96% \ttest: 96.87%\n",
      "180 : cost: 0.0757278 \ttrain: 98.086% \tvalid: 96.97% \ttest: 96.87%\n",
      "saving filters...\n",
      "181 : cost: 0.0753978 \ttrain: 98.088% \tvalid: 96.97% \ttest: 96.87%\n",
      "182 : cost: 0.0750704 \ttrain: 98.096% \tvalid: 96.97% \ttest: 96.88%\n",
      "183 : cost: 0.0747457 \ttrain: 98.1% \tvalid: 96.98% \ttest: 96.88%\n",
      "saving filters...\n",
      "184 : cost: 0.0744235 \ttrain: 98.114% \tvalid: 96.96% \ttest: 96.87%\n",
      "185 : cost: 0.0741039 \ttrain: 98.118% \tvalid: 96.98% \ttest: 96.9%\n",
      "186 : cost: 0.0737868 \ttrain: 98.13% \tvalid: 96.99% \ttest: 96.92%\n",
      "saving filters...\n",
      "187 : cost: 0.0734722 \ttrain: 98.132% \tvalid: 96.99% \ttest: 96.93%\n",
      "188 : cost: 0.07316 \ttrain: 98.142% \tvalid: 96.97% \ttest: 96.95%\n",
      "189 : cost: 0.0728503 \ttrain: 98.15% \tvalid: 96.97% \ttest: 96.97%\n",
      "saving filters...\n",
      "190 : cost: 0.0725429 \ttrain: 98.156% \tvalid: 96.97% \ttest: 96.97%\n",
      "191 : cost: 0.0722379 \ttrain: 98.17% \tvalid: 96.97% \ttest: 96.97%\n",
      "192 : cost: 0.0719353 \ttrain: 98.184% \tvalid: 96.97% \ttest: 96.99%\n",
      "saving filters...\n",
      "193 : cost: 0.0716349 \ttrain: 98.198% \tvalid: 96.98% \ttest: 96.99%\n",
      "194 : cost: 0.0713368 \ttrain: 98.21% \tvalid: 96.98% \ttest: 96.99%\n",
      "195 : cost: 0.071041 \ttrain: 98.222% \tvalid: 96.98% \ttest: 96.99%\n",
      "saving filters...\n",
      "196 : cost: 0.0707473 \ttrain: 98.226% \tvalid: 96.98% \ttest: 96.98%\n",
      "197 : cost: 0.0704559 \ttrain: 98.238% \tvalid: 96.98% \ttest: 96.98%\n",
      "198 : cost: 0.0701666 \ttrain: 98.252% \tvalid: 96.98% \ttest: 96.99%\n",
      "saving filters...\n",
      "199 : cost: 0.0698795 \ttrain: 98.266% \tvalid: 96.98% \ttest: 96.99%\n",
      "200 : cost: 0.0695945 \ttrain: 98.27% \tvalid: 96.98% \ttest: 96.99%\n"
     ]
    }
   ],
   "source": [
    "run(batch_size=100, epochs=200, check_frequency=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
